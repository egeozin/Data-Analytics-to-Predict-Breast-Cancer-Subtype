{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "plotly.plotly.sign_in('spersad', 'oNkuP1yzbpN734Ag8M9P')\n",
    "import plotly.graph_objs as go\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('fivethirtyeight')\n",
    "not_location_file = 'PATIENT_DATA_ALL_4.csv'\n",
    "location_file = 'PATIENT_DATA_LOCATION.csv'\n",
    "not_location = pd.read_csv(not_location_file, sep='\\t')\n",
    "location = pd.read_csv(location_file, sep='\\t')\n",
    "cna = pd.read_csv('data_CNA.xls.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna.set_index('Hugo_Symbol', inplace=True)\n",
    "cna.drop(['Entrez_Gene_Id'], axis=1,inplace=True)\n",
    "cna = cna.transpose()\n",
    "cna.sort_index(inplace=True)\n",
    "#cna = cna[:-1] # getting rid of the last row\n",
    "\n",
    "#merged.sort_values('SAMPLE_ID', ascending=False)\n",
    "not_location.set_index('SAMPLE_ID',inplace=True)\n",
    "not_location.drop('PATIENT_ID', axis=1,inplace=True)\n",
    "not_location.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
    "not_location.sort_index(inplace=True)\n",
    "\n",
    "location.drop('PATIENT_ID', axis=1,inplace=True)\n",
    "location.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
    "location.set_index('SAMPLE_ID', inplace=True)\n",
    "location.sort_index(inplace=True)\n",
    "\n",
    "clinical_n_cna = pd.concat([not_location, cna], axis=1)\n",
    "\n",
    "columns = list(location.columns)\n",
    "categories = list(range(len(columns)))\n",
    "category_dict = dict(zip(columns, categories))\n",
    "\n",
    "clinical_n_cna = clinical_n_cna.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = clinical_n_cna.as_matrix() \n",
    "Y = location.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomize = True\n",
    "if randomize:\n",
    "    random_indices = np.random.permutation(len(X))\n",
    "    # Randomized data\n",
    "    X_r = X[random_indices]\n",
    "    Y_r = Y[random_indices]\n",
    "\n",
    "# Select a training, test and validation set\n",
    "n_train = int(0.5*X.shape[0])\n",
    "n_val = int(0.1*X.shape[0])\n",
    "\n",
    "X_train, y_train = X_r[:n_train], Y_r[:n_train]\n",
    "X_val, y_val = X_r[n_train:n_train+n_val], Y_r[n_train:n_train+n_val]\n",
    "X_test, y_test = X_r[n_train+n_val:], Y_r[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2CN, train_samples=51, n_features=23184, n_classes=3\n",
      "Using l1 regression\n",
      "[model=One versus Rest, solver=liblinear] Number of epochs: 1\n",
      "[model=One versus Rest, solver=liblinear] Number of epochs: 3\n",
      "Test accuracy for model ovr: 17.9756\n",
      "Train accuracy for model ovr: 21.5098\n",
      "Validation accuracy for model ovr: 18.7000\n",
      "Run time (3 epochs) for model ovr:4.64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "tr_accuracies",
         "type": "scatter",
         "x": [
          0,
          4.706545,
          4.63513
         ],
         "y": [
          0.3333333333333333,
          21.50980392156863,
          21.50980392156863
         ]
        },
        {
         "name": "val_accuracies",
         "type": "scatter",
         "x": [
          0,
          4.706545,
          4.63513
         ],
         "y": [
          0.3333333333333333,
          18.7,
          18.7
         ]
        },
        {
         "name": "test_accuracies",
         "type": "scatter",
         "x": [
          0,
          4.706545,
          4.63513
         ],
         "y": [
          0.3333333333333333,
          17.975609756097562,
          17.975609756097562
         ]
        }
       ],
       "layout": {
        "title": "Accuracy for ovr model",
        "xaxis": {
         "title": "Time"
        },
        "yaxis": {
         "title": "Accuracy"
        }
       }
      },
      "text/html": [
       "<div id=\"c2c5818d-5938-417b-9e19-ecde67be064f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c2c5818d-5938-417b-9e19-ecde67be064f\", [{\"type\": \"scatter\", \"x\": [0, 4.706545, 4.63513], \"y\": [0.3333333333333333, 21.50980392156863, 21.50980392156863], \"name\": \"tr_accuracies\"}, {\"type\": \"scatter\", \"x\": [0, 4.706545, 4.63513], \"y\": [0.3333333333333333, 18.7, 18.7], \"name\": \"val_accuracies\"}, {\"type\": \"scatter\", \"x\": [0, 4.706545, 4.63513], \"y\": [0.3333333333333333, 17.975609756097562, 17.975609756097562], \"name\": \"test_accuracies\"}], {\"yaxis\": {\"title\": \"Accuracy\"}, \"title\": \"Accuracy for ovr model\", \"xaxis\": {\"title\": \"Time\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"c2c5818d-5938-417b-9e19-ecde67be064f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c2c5818d-5938-417b-9e19-ecde67be064f\", [{\"type\": \"scatter\", \"x\": [0, 4.706545, 4.63513], \"y\": [0.3333333333333333, 21.50980392156863, 21.50980392156863], \"name\": \"tr_accuracies\"}, {\"type\": \"scatter\", \"x\": [0, 4.706545, 4.63513], \"y\": [0.3333333333333333, 18.7, 18.7], \"name\": \"val_accuracies\"}, {\"type\": \"scatter\", \"x\": [0, 4.706545, 4.63513], \"y\": [0.3333333333333333, 17.975609756097562, 17.975609756097562], \"name\": \"test_accuracies\"}], {\"yaxis\": {\"title\": \"Accuracy\"}, \"title\": \"Accuracy for ovr model\", \"xaxis\": {\"title\": \"Time\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example run in 9.815 s\n"
     ]
    }
   ],
   "source": [
    "# Turn down for faster run time\n",
    "n_samples = 10000\n",
    "\n",
    "penalty = 'l1'\n",
    "\n",
    "train_samples, n_features = X_train.shape\n",
    "n_classes = np.unique(Y).shape[0]\n",
    "\n",
    "t0 = time.clock()\n",
    "\n",
    "print('Dataset 2CN, train_samples=%i, n_features=%i, n_classes=%i'\n",
    "      % (train_samples, n_features, n_classes))\n",
    "\n",
    "models = {'ovr': {'name': 'One versus Rest', 'iters': [1, 3, 7, 11, 13, 15]},\n",
    "          'multinomial': {'name': 'Multinomial', 'iters': [1, 3, 7, 11, 13, 15]}}\n",
    "\n",
    "# Solver which handles multiclass and l1 penalty\n",
    "solver = 'newton-cg'\n",
    "\n",
    "if penalty == 'l1':\n",
    "    print('Using l1 regression')\n",
    "    models = {'ovr': {'name': 'One versus Rest', 'iters': [1, 3]}}\n",
    "    solver = 'liblinear'\n",
    "    \n",
    "for model in models:\n",
    "    # Add initial chance-level values for plotting purpose\n",
    "    test_accuracies = [1 / n_classes]\n",
    "    tr_accuracies = [1/n_classes]\n",
    "    val_accuracies = [1/n_classes]\n",
    "    times = [0]\n",
    "    densities = [1]\n",
    "\n",
    "    model_params = models[model]\n",
    "\n",
    "    # Small number of epochs for fast runtime\n",
    "    for this_max_iter in model_params['iters']:\n",
    "        print('[model=%s, solver=%s] Number of epochs: %s' %\n",
    "              (model_params['name'], solver, this_max_iter))\n",
    "        #lr = LogisticRegression(solver=solver,multi_class=model,C=1,penalty=penalty,fit_intercept=True, max_iter=this_max_iter, random_state=42)\n",
    "        max_depth = 30\n",
    "        lr = MultiOutputRegressor(RandomForestRegressor(max_depth=max_depth,\n",
    "                                                          random_state=0))\n",
    "        t1 = time.clock()\n",
    "        lr.fit(X_train, y_train)\n",
    "        train_time = time.clock() - t1\n",
    "\n",
    "        y_pred = lr.predict(X_test)\n",
    "        accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n",
    "        #density = np.mean(lr.get_params(deep=True) != 0, axis=1) * 100\n",
    "        tr_accuracy = np.sum(y_train == lr.predict(X_train)) / y_train.shape[0]\n",
    "        val_accuracy = np.sum(y_val == lr.predict(X_val)) / y_val.shape[0]\n",
    "        \n",
    "        test_accuracies.append(accuracy)\n",
    "        #densities.append(density)\n",
    "        tr_accuracies.append(tr_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        times.append(train_time)\n",
    "    models[model]['times'] = times\n",
    "    #models[model]['densities'] = densities\n",
    "    models[model]['test_accuracies'] = test_accuracies\n",
    "    models[model]['tr_accuracies'] = tr_accuracies\n",
    "    models[model]['val_accuracies'] = val_accuracies\n",
    "    \n",
    "    print('Test accuracy for model %s: %.4f' % (model, test_accuracies[-1]))\n",
    "    print('Train accuracy for model %s: %.4f' % (model, tr_accuracies[-1]))\n",
    "    print('Validation accuracy for model %s: %.4f' % (model, val_accuracies[-1]))\n",
    "    #print('%% non-zero coefficients for model %s, '\n",
    "    #     'per class:\\n %s' % (model, densities[-1]))\n",
    "    print('Run time (%i epochs) for model %s:'\n",
    "          '%.2f' % (model_params['iters'][-1], model, times[-1]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for model in models:\n",
    "    data = []\n",
    "    for accuracy in ['tr_accuracies', 'val_accuracies','test_accuracies']:\n",
    "        \n",
    "        trace = go.Scatter(\n",
    "                            x = models[model]['times'],\n",
    "                            y = models[model][accuracy],\n",
    "                            name = accuracy\n",
    "                        )\n",
    "\n",
    "        data.append(trace)\n",
    "    layout = go.Layout(\n",
    "        title = 'Accuracy for {0} model'.format(model),\n",
    "        xaxis = dict(title = 'Time'),\n",
    "        yaxis = dict(title = 'Accuracy'),\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "        \n",
    "run_time = time.clock() - t0\n",
    "print('Example run in %.3f s' % run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_regression(X_r, Y_r, penalty = 'l2', per_train=0.4, per_val=0.15):\n",
    "    \n",
    "    # Select a training, test and validation set\n",
    "\n",
    "    n_train = int(per_train*X_r.shape[0])\n",
    "    n_val = int(per_val*X_r.shape[0])\n",
    "\n",
    "\n",
    "    X_test, y_test = X_r[:n_train], Y_r[:n_train]\n",
    "    X_val, y_val = X_r[n_train:n_train+n_val], Y_r[n_train:n_train+n_val]\n",
    "    X_train, y_train = X_r[n_train+n_val:], Y_r[n_train+n_val:]\n",
    "\n",
    "    # How many of each cancer type are in the train, test and validations set?\n",
    "    tr_count = y_train.value_counts()/np.sum( y_train.value_counts())\n",
    "    val_count = y_val.value_counts()/np.sum(y_val.value_counts())\n",
    "    te_count = y_test.value_counts()/np.sum(y_test.value_counts())\n",
    "\n",
    "\n",
    "    # Plot the distribution of test, train and val points. Will throw a KeyError if any\n",
    "    try:\n",
    "        trace1 = go.Bar(\n",
    "            x=['BREAST','IDC', 'MDLC', 'ILC'],\n",
    "            y=[tr_count[i] for i in range(4)],\n",
    "            name='Training Set'\n",
    "        )\n",
    "        trace2 = go.Bar(\n",
    "            x=['BREAST','IDC', 'MDLC', 'ILC'],\n",
    "            y=[val_count[i] for i in range(4)],\n",
    "            name='Validation Set'\n",
    "        )\n",
    "\n",
    "        trace3 = go.Bar(\n",
    "            x=['BREAST','IDC', 'MDLC', 'ILC'],\n",
    "            y=[te_count[i] for i in range(4)],\n",
    "            name='Test Set'\n",
    "        )\n",
    "\n",
    "        data = [trace1, trace2, trace3]\n",
    "        layout = go.Layout(\n",
    "            barmode='group',\n",
    "            title = 'Distribution of Categories over Data Sets',\n",
    "            xaxis = dict(title = 'Categories'),\n",
    "            yaxis = dict(title = 'Percentage of Data Set'),\n",
    "        )\n",
    "\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        iplot(fig, filename='grouped-bar')\n",
    "\n",
    "    except:\n",
    "        print(tr_count)\n",
    "        print(val_count)\n",
    "        print(te_count)\n",
    "        print('One of the data sets does not contain all the categories!')\n",
    "        assert False\n",
    "\n",
    "    # plot the training data in two dimensions\n",
    "    performPCA(X_train, y_train)\n",
    "    \n",
    "    t0 = time.clock()\n",
    "\n",
    "    train_samples, n_features = X_train.shape\n",
    "    n_classes = np.unique(Y).shape[0]\n",
    "\n",
    "    print('Dataset 2CN, train_samples=%i, n_features=%i, n_classes=%i'\n",
    "          % (train_samples, n_features, n_classes))\n",
    "\n",
    "    models = {'ovr': {'name': 'One versus Rest', 'iters': [1, 3, 7, 11, 13, 15, 17, 21]},\n",
    "              'multinomial': {'name': 'Multinomial', 'iters': [1, 3, 7, 11, 13, 15, 17, 21]}}\n",
    "\n",
    "    # Solver which handles multiclass and l1 penalty\n",
    "    solver = 'newton-cg'\n",
    "\n",
    "    if penalty == 'l1':\n",
    "        print('Using l1 regression')\n",
    "        models = {'ovr': {'name': 'One versus Rest', 'iters': [1, 3, 7, 11, 13, 15, 17, 21]}}\n",
    "        solver = 'liblinear'\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    best_model = None \n",
    "    \n",
    "    def get_acc(y_true, y_pred):\n",
    "        #F1 score\n",
    "        from sklearn.metrics import f1_score\n",
    "        return f1_score(y_true, y_pred)\n",
    "    \n",
    "        #accuracy\n",
    "        return np.sum(y_true == y_pred) / y_true.shape[0]\n",
    "        return \n",
    "    \n",
    "    \n",
    "    for model in models:\n",
    "        # Add initial chance-level values for plotting purpose\n",
    "        test_accuracies = [1 / n_classes]\n",
    "        tr_accuracies = [1/n_classes]\n",
    "        val_accuracies = [1/n_classes]\n",
    "        times = [0]\n",
    "        densities = [1]\n",
    "\n",
    "        model_params = models[model]\n",
    "\n",
    "        # Small number of epochs for fast runtime\n",
    "        for this_max_iter in model_params['iters']:\n",
    "            print('[model=%s, solver=%s] Number of epochs: %s' %\n",
    "                  (model_params['name'], solver, this_max_iter))\n",
    "            lr = LogisticRegression(solver=solver,\n",
    "                                    multi_class=model,\n",
    "                                    C=1,\n",
    "                                    penalty=penalty,\n",
    "                                    fit_intercept=True,\n",
    "                                    max_iter=this_max_iter,\n",
    "                                    random_state=42,\n",
    "                                    )\n",
    "            \n",
    "            lr.fit(X_train, y_train)\n",
    "            \n",
    "            accuracy = get_acc(y_test,lr.predict(X_test))\n",
    "            density = np.mean(lr.coef_ != 0, axis=1) * 100\n",
    "            tr_accuracy = get_acc(y_train,lr.predict(X_train))\n",
    "            val_accuracy = get_acc(y_val, lr.predict(X_val))\n",
    "\n",
    "            test_accuracies.append(accuracy)\n",
    "            densities.append(density)\n",
    "            tr_accuracies.append(tr_accuracy)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            times.append(this_max_iter)\n",
    "            \n",
    "            if accuracy>best_val_accuracy:\n",
    "                best_model = lr\n",
    "                \n",
    "        models[model]['times'] = times\n",
    "        models[model]['densities'] = densities\n",
    "        models[model]['test_accuracies'] = test_accuracies\n",
    "        models[model]['tr_accuracies'] = tr_accuracies\n",
    "        models[model]['val_accuracies'] = val_accuracies\n",
    "\n",
    "        print('Test accuracy for model %s: %.4f' % (model, test_accuracies[-1]))\n",
    "        print('Train accuracy for model %s: %.4f' % (model, tr_accuracies[-1]))\n",
    "        print('Validation accuracy for model %s: %.4f' % (model, val_accuracies[-1]))\n",
    "        print('%% non-zero coefficients for model %s, '\n",
    "              'per class:\\n %s' % (model, densities[-1]))\n",
    "        print('Run time (%i epochs) for model %s:'\n",
    "              '%.2f' % (model_params['iters'][-1], model, times[-1]))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    for model in models:\n",
    "        data = []\n",
    "        for accuracy in ['tr_accuracies', 'val_accuracies','test_accuracies']:\n",
    "            trace = go.Scatter(\n",
    "                                x = models[model]['times'],\n",
    "                                y = models[model][accuracy],\n",
    "                                name = accuracy\n",
    "                            )\n",
    "\n",
    "            data.append(trace)\n",
    "        layout = go.Layout(\n",
    "            title = 'Accuracy for {0} model'.format(model),\n",
    "            xaxis = dict(title = 'Iterations'),\n",
    "            yaxis = dict(title = 'Accuracy'),\n",
    "        )\n",
    "\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        iplot(fig)\n",
    "\n",
    "    run_time = time.clock() - t0\n",
    "    print('Example run in %.3f s' % run_time)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    c = confusion_matrix(y_test, best_model.predict(X_test))\n",
    "\n",
    "    trace = go.Heatmap(z=(c.T/np.sum(c,axis=1)).T,                   \n",
    "                       x=['BREAST','IDC', 'MDLC', 'ILC'],\n",
    "                       y=['BREAST','IDC', 'MDLC', 'ILC'])\n",
    "    data=[trace]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = 'Confusion Matrix for Test Predictions',\n",
    "        xaxis = dict(title = 'Predicted'),\n",
    "        yaxis = dict(title = 'Truth'),\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    \n",
    "    c = confusion_matrix(y_train, best_model.predict(X_train))\n",
    "    trace = go.Heatmap(z=(c.T/np.sum(c,axis=1)).T,                   \n",
    "                       x=['BREAST','IDC', 'MDLC', 'ILC'],\n",
    "                       y=['BREAST','IDC', 'MDLC', 'ILC'])\n",
    "    data=[trace]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = 'Confusion Matrix for Training Predictions',\n",
    "        xaxis = dict(title = 'Predicted'),\n",
    "        yaxis = dict(title = 'Truth'),\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "\n",
    "\n",
    "    return best_model, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
